#include <iostream>
#include "taco.h"
#include "kernels.hpp"

using namespace taco;
using namespace std::chrono;

const IndexVar i("i"), j("j"), k("k"), l("l"), m("m"), n("n");
int WARP_SIZE = 32;

float measure_time(std::function<float()> runner) {
  // int w_iters = 1000;
  // int a_iters = 1000;
  int w_iters = 10;
  int a_iters = 10;
  for (int i = 0; i < w_iters; ++i) {
    runner();
  }

  float exe_time = 0.0;
  for (int i = 0; i < a_iters; ++i) {
        exe_time += runner();
  }

  return exe_time / a_iters;
}

IndexStmt scheduleSpMMGPU(IndexStmt stmt, Tensor<float> A, int m, IndexExpr precomputedExprA,
			  IndexExpr precomputedExprB, int NNZ_PER_WARP=8, int BLOCK_SIZE=256) {
  int NNZ_PER_TB = NNZ_PER_WARP * (BLOCK_SIZE / WARP_SIZE);
  IndexVar f("f"), fpos("fpos"), block("block"), fpos1("fpos1"), warp("warp"), nnz("nnz"), nnz_pre("nnz_pre");
  IndexVar dense_val_unbounded("dense_val_unbounded"), dense_val("dense_val"), thread("thread");
  IndexVar thread_nz("thread_nz");
  TensorVar precomputedA("precomputedA", Type(Float32, {Dimension(nnz)}), taco::dense);
  TensorVar precomputedB("precomputedB", Type(Float32, {Dimension(nnz)}), taco::dense);
  return stmt.reorder({i, j, k})
          .fuse(i, j, f)
          .pos(f, fpos, A(i, j))
          .split(fpos, block, fpos1, NNZ_PER_TB)
          .split(fpos1, warp, nnz, NNZ_PER_WARP)
          .split(k, dense_val_unbounded, thread, WARP_SIZE)
          .reorder({block, warp, thread, dense_val_unbounded, nnz})
          // .precompute(precomputedExprA, nnz, nnz, precomputedA)
          // .precompute(precomputedExprB, nnz, nnz, precomputedB)
          // .bound(dense_val_unbounded, dense_val, m / 32, BoundType::MaxExact)
          .bound(dense_val_unbounded, dense_val, -1, BoundType::MaxExact)
          .unroll(dense_val, 4)
          .parallelize(block, ParallelUnit::GPUBlock, OutputRaceStrategy::IgnoreRaces)
          .parallelize(warp, ParallelUnit::GPUWarp, OutputRaceStrategy::IgnoreRaces)
          .parallelize(thread, ParallelUnit::GPUThread, OutputRaceStrategy::Atomics);
}

int main(int argc, char* argv[]) {
  int m = std::atoi(argv[1]);
  int combined = (bool)(std::atoi(argv[2]));
  int nnzpw = std::atoi(argv[3]);
  int bs = std::atoi(argv[4]);
  int NUM_I = m;
  int NUM_J = m;
  int NUM_K = m;
  // int NUM_I = 1021/10;
  // int NUM_J = 1039/10;
  // int NUM_K = 128;
  float SPARSITY = .3;
  Tensor<float> A("A", {NUM_I, NUM_J}, CSR);
  Tensor<float> B("B", {NUM_J, NUM_K}, {Dense, Dense});
  Tensor<float> C("C", {NUM_I, NUM_K}, Format({{Dense, Dense}, {1, 0}}));

  srand(434321);
  for (int i = 0; i < NUM_I; i++) {
    for (int j = 0; j < NUM_J; j++) {
      if (j <= i) {
	float rand_float = (float)rand()/(float)(RAND_MAX);
	A.insert({i, j}, (float) ((int) (rand_float*3/SPARSITY)));
      }
    }
  }

  for (int j = 0; j < NUM_J; j++) {
    for (int k = 0; k < NUM_K; k++) {
      float rand_float = (float)rand()/(float)(RAND_MAX);
      B.insert({j, k}, (float) ((int) (rand_float*3/SPARSITY)));
    }
  }

  A.pack();
  B.pack();
  IndexExpr precomputedA = A(i, j);
  IndexExpr precomputedB = B(j, k);
  C(i, k) += precomputedB * precomputedA;

  C.setAssembleWhileCompute(combined);

  IndexStmt stmt = C.getAssignment().concretize();
  stmt = scheduleSpMMGPU(stmt, A, m, precomputedA, precomputedB, nnzpw, bs);

  C.compile(stmt);

  auto At = A.getTacoTensorT();
  auto Bt = B.getTacoTensorT();
  auto Ct = C.getTacoTensorT();

  compute(Ct, At, Bt, 2048);

  // int A1_dimension = (int)(At->dimensions[0]);
  // int* __restrict__ A2_pos = (int*)(At->indices[1][0]);
  // std::cout << "[BLOCKS] " << ((A2_pos[A1_dimension] + 63) / 64) << std::endl;

  // std::cout << "[YOLO] Source: " << C.getSource() << std::endl;

  // auto assembly_runner = [&]() {
  // 			   time_point<system_clock> start = system_clock::now();
  // 			   C.assemble();
  // 			   time_point<system_clock> end = system_clock::now();
  // 			   duration<float> exe_time = (end - start);
  // 			   return duration_cast<microseconds>(exe_time).count() * 0.001;
  // 			 };
  // if (!combined) {
  //   std::cout << "[YOLO] Assembly time: " << measure_time(assembly_runner) << std::endl;
  // }

  // auto compute_runner = [&]() {
  // 			  time_point<system_clock> start = system_clock::now();
  // 			  C.compute();
  // 			  time_point<system_clock> end = system_clock::now();
  // 			  duration<float> exe_time = (end - start);
  // 			  return duration_cast<microseconds>(exe_time).count() * 0.001;
  // 			};
  // std::cout << "[YOLO] Compute time: " << measure_time(compute_runner) << std::endl;
}
